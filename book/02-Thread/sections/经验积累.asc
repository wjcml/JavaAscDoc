=== 记一次多线程研发遇到的坑

==== 问题背景
----
1. 开发一套经验支持系统，就是通过创建公共的经验模型和规则，然后由模型获取并整合数据，将数据输入规则中，得到返回结果。
2. 难点: 模型中存在多个对象（M），并且每个对象可以通过SQL获取API获取多个数据（N），也就是说，跑一次模型，一个规则需要被执行 M 次，并且需要查询数据 M * N 次。
3. 目标: 降低跑一次模型需要用的时间，提升速度。
----
如下图:

image::多线程遇到的坑-业务逻辑图.png[]


==== 研发方案的迭代

----
1. for循环
2. 线程池框架 ThreadPoolExecutor（Disruptor，gitee-京东零售）
----

==== 遇到的坑

===== 1、死锁
----
出现问题的原因:
1. 只定义了一个线程池
2. 自定义了 10 个核心线程数
3. 有 60 个对象需要执行规则逻辑（下面用 A 代替），每个对象需要 调用 2 个api接口获取数据
4. 如果有 10 个 A 占用了 10 个线程，但是他们需要等待 api 接口获取到数据才能继续执行，但是查数据的任务又在等待队列中，等待核心线程资源释放，这时就会一直等待

解决办法:
1. 创建两个线程池分别执行这两种任务
----

===== 2、经典线程安全问题
----
出现问题的原因:
1. 多个线程中对同一个对象中的属性进行修改

解决办法:
1. 禁止在多线程中对同一个对象的属性进行修改
2. 使用JUC下的线程安全对象
3. 在子线程中创建新的对象接受需要修改的值，最后通过线程返回值返回
4. 对数据操作方法加锁（不推荐）
----


===== 3、内存泄漏问题

====== (1) 问题描述
----
在项目部署后，一开始模型和模型实例较少，程序的负担较低，没有发现问题。但是随着模型和模型实例的数量越来越多，我们发现内存占用上涨的非常快，一天的时间就可以将4个G的内存占满（内存泄漏）。
----

====== (2) 可能的原因

----
1. 项目是使用观云台（公司的产品）部署的，因此程序是在 K8s 的 Pod 中运行的。在pod中运行的程序打印日志（输出日志到控制台和写日志到日志文件）是会占用大量的内存的。该项目本身是一个多线程运行模型的程序，为了方便排查问题，日志打印的也比较多，所以造成pod的内存被大量占用。

2. 程序中存在对象一直没有被释放，导致内存泄漏。
----

[NOTE]
====
TODO: 为什么打印大量的日志会造成内存占用过高？后续讨论...
====

====== (3) 解决办法

----
1. 在正式环境中，日志的打印等级要调低一些，尽量使用 Error 作为日志输出等级。

2. 排查程序中是否有对象没有被回收掉，导致内存泄漏，然后修改代码。（排查过程在后续中会些出来）
----


====== (4) 排查内存泄漏的原因

说明：异常管控服务是通过 K8s 进行部署的。

- 首先第一步进入到部署的容器中，命令： *docker exec -it 容器名 /bin/bash*
- 然后查看java进程列表，命令： *ps -ef | grep java*

image::查看java进程.png[]

- 通过 *jmap* 命令，查看查看堆内存的使用情况，命令：*jmap -heap 进程id*
----
堆内存详情参数解释：

Heap Configuration:         ## 堆配置情况，也就是JVM参数配置的结果[平常说的tomcat配置JVM参数，就是在配置这些]
   MinHeapFreeRatio         = 40                            //JVM堆最小空闲比率(default 40)
   MaxHeapFreeRatio         = 70                            //JVM堆最大空闲比率(default 70)
   MaxHeapSize              = 402653184 (384.0MB)           //JVM堆的最大大小
   NewSize                  = 8388608 (8.0MB)               //JVM堆的‘新生代’的默认大小
   MaxNewSize               = 134217728 (128.0MB)           //JVM堆的‘新生代’的最大大小
   OldSize                  = 16777216 (16.0MB)             //JVM堆的‘老生代’的大小
   NewRatio                 = 2                             //‘新生代’和‘老生代’的大小比率
   SurvivorRatio            = 8                             //年轻代中Eden区与Survivor区的大小比值
   MetaspaceSize            = 21807104 (20.796875MB)        //元空间大小
   CompressedClassSpaceSize = 1073741824 (1024.0MB)         //元空间中类区域的大小
   MaxMetaspaceSize         = 17592186044415 MB             //元空间最大值，设置这么大，意思是让jvm自己去管理
   G1HeapRegionSize         = 0 (0.0MB)

Heap Usage:                ## 堆内存分布
New Generation (Eden + 1 Survivor Space):                   //新生代（Eden区 + survior(from + to)空间）
   capacity = 70713344 (67.4375MB)                          //新生代区容量
   used     = 38155000 (36.38744354248047MB)                //新生代区已经使用大小
   free     = 32558344 (31.05005645751953MB)                //新生代区剩余容量
   53.95728421498494% used                                  //使用比例
Eden Space:                                                 //Eden区容量
   capacity = 62914560 (60.0MB)
   used     = 37078688 (35.360992431640625MB)
   free     = 25835872 (24.639007568359375MB)
   58.93498738606771% used
From Space:                                                 //from survior
   capacity = 7798784 (7.4375MB)
   used     = 1076312 (1.0264511108398438MB)
   free     = 6722472 (6.411048889160156MB)
   13.801023339023109% used
To Space:                                                   //to survior
   capacity = 7798784 (7.4375MB)
   used     = 0 (0.0MB)
   free     = 7798784 (7.4375MB)
   0.0% used
PS Old Generation:                                         //老年代
   capacity = 156958720 (149.6875MB)
   used     = 125501120 (119.68719482421875MB)
   free     = 31457600 (30.00030517578125MB)
   79.95804247129436% used
----

- 查看java进程中的堆内存对象数量情况，命令： *jmap -histo:live 进程id*

下面三张图是服务不同时期，堆内存对象数量情况：

&emsp;&emsp;1.服务已启动，未运行模型的堆内存中对象数量情况

image::堆内存对象数量情况03.png[]

&emsp;&emsp;2.服务已启动，在执行模型，服务启动时间不长的堆内存对象数量情况

image::堆内存对象数量情况01.png[]

&emsp;&emsp;3.服务已启动，在执行模型，运行了一段时间后，快到达最大堆内存   的堆内存对象数量情况

image::堆内存对象数量情况02.png[]

&emsp;&emsp;从上面三张图中可以看出，服务随着运行时间的增加，内存占用越来越高，可以看出有很多的对象数量一直再增加，比如 *ThreadLocalMap* 对象。一开始我看到这个的时候，还以为是某个 ThreadLocal 使用后没有被回收，造成内存泄漏。然后我立马去看代码，经过仔细的排查后，所有的 ThreadLocal 都在使用后，及时的调用了 clear() 方法的，所以并不是 ThreadLocal 造成内存缓慢增长的。

- 把进程的内存使用情况dump到文件中，使用命令：*jmap -dump:format=b,file=文件名.hprof 进程id*

&emsp;&emsp;然后将该文件下载到本地，使用 *MemoryAnalyzer* 工具，查询内存使用情况。

image::java内存dump文件分析01.png[]

从上图中可以看出 ThreadLocalMap 在哪个线程中，经过一系列的排查，导致内存缓慢升高的原因是：*进程中的线程数量一直在增加* ，由于线程是通过线程池创建的，模型实例的数量也很多，并发很高，所以线程基本是一直处于占用状态，然后随着线程数量的增加，内存占用就越来越高。

最终解决方案：根据我们的线程池配置，当线程池的核心数量使用完后，堆内存占用大概 3G，所以我们配置了堆内存大小 4G。



=== 记一次实战项目遇到的问题和解决方案（智能决策平台）

智能决策平台实现的主要功能：获取到多个数据，然后将数据经由专业的业务规则和历史数据的数学模型，最终生成决策结果。

产生以下问题的大部分原因在于数据量太大，或者并发太高了。在只有一个租户的的情况下，气田生产业务域一天能产生 7G 的数据，石油工程一天能产生 12G 的数据。

==== 问题一

===== (1) 问题描述

----
为了提高模型执行效率，项目中采用了多线程的的方式执行模型实例和查询每个实例的执行数据。采用多线程就会涉及到线程池的配置问题，线程池数量配置的过高或者过低，都会导致模型执行时间过长。
----

===== (2) 解决方案

----
该系统是一个IO密集型的，我们也做过相关调研，网上说的IO密集型的 线程数等于CPU核心数 * 2，CPU密集型的线程数等于CPU核心数 + 1；在这个系统中是不适用的，很是得根据实际情况来配置。
通过大量的测试，得出结论，规则执行的线程池线程数 ：查询执行数据的线程池线程数 = 1:5 （或1:4）为最优配置。
----

===== (2) 实际配置如下
实际配置可能没有按照 1:5 进行配置

[source, xml]
----
# 线程池配置
thread-pool:
  async-task:
    # 执行模型规则的线程池
    rule-exec:
      core-pool-size: 1500
      max-pool-size: 3000
      keep-alive-time: 30
      queue-capacity: 20000
      thread-name-prefix: rule-executor-thread-
      # 拒绝策略：CallerRunsPolicy，AbortPolicy，DiscardPolicy，DiscardOldestPolicy
      rejected-policy: CallerRunsPolicy
    # 执行规则时，数据集查询数据的线程池
    dataset-exec:
      core-pool-size: 5000
      max-pool-size: 10000
      keep-alive-time: 30
      queue-capacity: 20000
      thread-name-prefix: dataset-executor-thread-
      # 拒绝策略：CallerRunsPolicy，AbortPolicy，DiscardPolicy，DiscardOldestPolicy
      rejected-policy: CallerRunsPolicy
----


==== 问题二

===== (1) 问题描述

----
系统采用Elasticsearch保存模型执行有大量的执行记录和告警记录，Es频繁报错，有大量的数据保存失败，造成数据丢失。（注：Es的配置是三主三从，八核20G内存，1T的存储）
----

===== (2) 原因
----
由于模型大部分是定时任务触发，任务触发后，采用多线程的方式保存执行记录，并且项目是多实例部署的，使得Es承载的并发太高，然后数据频繁失败。
----

===== (3) 解决方案

----
1. 添加了重试次数，模型实例数量增加到一定数量，还是会有很多数据保存失败。
2. 将执行记录放入到内存中，然后使用 CommandLineRunner 启动一个线程，一直去内存中取数据，然后批量保存到ES，降低ES的请求频率，从而降低压力。
3. 为了保证执行记录全部保存成功，采用优雅停机的方式，接收到 kill -2 的信号后，会等待一定的时间再停止服务。
----


==== 问题三

===== (1) 问题描述

----
模型在执行过程中，数据库查询缓慢，导致执行时间过长的问题。
----

===== (2) 原因
----
1. 数据库查询次数过多，数据库压力太大了（数据库已经是主从配置了）。
2. 系统配置的数据源连接数太少。
3. MySQL本身配置的最大连接数太少，当有多个服务的实例（Pod）连接数据库时，连接不够用。（主要是该数据库是采用容器部署的，为了能资源利用最大化，所以在部署MySQL服务器时，给数据库配置的有些资源都比较低）
----

===== (3) 解决方案

----
1. 能够使用Redis的地方尽量使用Redis。
2. 系统要配置合适的数据源连接配置。
3. 调整好数据库应该分配足够的资源和配置好MySQL本身的配置。
----


==== 问题三

===== (1) 问题描述

----
在模板中有大量的SQL查询数据集，导致模型执行时间过长；并且由于查询时间很长，会使得其一直占用的线程，导致其他模型的执行时间很长，告警消息滞后，不能准时告警。
----

===== (2) 原因
----
1. SQL请求频率高，数据库查询压力大。
2. SQL非常复杂，有的SQL不走索引；有的SQL中做了大量计算；有的SQL有大量的子查询；对同一张表多次扫描。
----

===== (3) 解决方案

----
1. 对部分数据做缓存，筛选出可以做缓存的数据集（该数据集的SQL简单，查询的表数据更新不频繁），通过canal配置监控表，如果发生变化，更新对应数据就可以了。
2. 将执行缓慢的模型筛选出来，单独部署一套执行这些模型的环境，增加机器资源，避免这些执行缓慢的模型影响到执行很快的模型。
3. 将变化频繁的数据，（比如实时录井数据）存入缓存，然后在提供查询缓存的API接口，以API接口查询缓存，减少对数据库的查询次数。
----
